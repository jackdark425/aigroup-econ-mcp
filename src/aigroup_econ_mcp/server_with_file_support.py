"""
AIGroup è®¡é‡ç»æµå­¦ MCP æœåŠ¡å™¨ - æ”¯æŒCSVæ–‡ä»¶è·¯å¾„è¾“å…¥
ä½¿ç”¨æœ€æ–°çš„MCPç‰¹æ€§æä¾›ä¸“ä¸šè®¡é‡ç»æµå­¦åˆ†æå·¥å…·
"""

from typing import List, Dict, Any, Optional, Annotated, Union
from collections.abc import AsyncIterator
from contextlib import asynccontextmanager
from dataclasses import dataclass
import json
from pathlib import Path

import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.tsa import stattools
from scipy import stats
from pydantic import BaseModel, Field

from mcp.server.fastmcp import FastMCP, Context
from mcp.server.session import ServerSession
from mcp.types import CallToolResult, TextContent


# æ•°æ®æ¨¡å‹å®šä¹‰
class DescriptiveStatsResult(BaseModel):
    """æè¿°æ€§ç»Ÿè®¡ç»“æœ"""
    count: int = Field(description="æ ·æœ¬æ•°é‡")
    mean: float = Field(description="å‡å€¼")
    std: float = Field(description="æ ‡å‡†å·®")
    min: float = Field(description="æœ€å°å€¼")
    max: float = Field(description="æœ€å¤§å€¼")
    median: float = Field(description="ä¸­ä½æ•°")
    skewness: float = Field(description="ååº¦")
    kurtosis: float = Field(description="å³°åº¦")


# åº”ç”¨ä¸Šä¸‹æ–‡
@dataclass
class AppContext:
    """åº”ç”¨ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«å…±äº«èµ„æº"""
    config: Dict[str, Any]
    version: str = "0.2.0"


@asynccontextmanager
async def lifespan(server: FastMCP) -> AsyncIterator[AppContext]:
    """æœåŠ¡å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    config = {
        "max_sample_size": 10000,
        "default_significance_level": 0.05,
        "supported_tests": ["t_test", "f_test", "chi_square", "adf"],
        "data_types": ["cross_section", "time_series", "panel"]
    }
    try:
        yield AppContext(config=config, version="0.2.0")
    finally:
        pass


# åˆ›å»ºMCPæœåŠ¡å™¨å®ä¾‹
mcp = FastMCP(
    name="aigroup-econ-mcp",
    instructions="Econometrics MCP Server with CSV file path support",
    lifespan=lifespan
)


# è¾…åŠ©å‡½æ•°ï¼šåŠ è½½CSVæ–‡ä»¶
async def load_data_from_path(file_path: str, ctx: Context) -> Dict[str, List[float]]:
    """ä»CSVæ–‡ä»¶è·¯å¾„åŠ è½½æ•°æ®"""
    await ctx.info(f"æ­£åœ¨ä»æ–‡ä»¶åŠ è½½æ•°æ®: {file_path}")
    
    try:
        # è¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(file_path)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        data = {col: df[col].tolist() for col in df.columns}
        
        await ctx.info(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸï¼š{len(df.columns)}ä¸ªå˜é‡ï¼Œ{len(df)}ä¸ªè§‚æµ‹")
        return data
        
    except FileNotFoundError:
        raise ValueError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    except Exception as e:
        raise ValueError(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")


@mcp.tool()
async def descriptive_statistics(
    ctx: Context[ServerSession, AppContext],
    data: Annotated[
        Union[Dict[str, List[float]], str],
        Field(
            description="""æ•°æ®è¾“å…¥ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š

ğŸ“Š æ ¼å¼1ï¼šæ•°æ®å­—å…¸
{
    "GDPå¢é•¿ç‡": [3.2, 2.8, 3.5, 2.9],
    "é€šè´§è†¨èƒ€ç‡": [2.1, 2.3, 1.9, 2.4],
    "å¤±ä¸šç‡": [4.5, 4.2, 4.0, 4.3]
}

ğŸ“ æ ¼å¼2ï¼šCSVæ–‡ä»¶è·¯å¾„ï¼ˆæ¨èï¼‰
"d:/data/economic_data.csv"
æˆ–
"./test_data.csv"

CSVæ–‡ä»¶è¦æ±‚ï¼š
- ç¬¬ä¸€è¡Œä¸ºå˜é‡åï¼ˆè¡¨å¤´ï¼‰
- åç»­è¡Œä¸ºæ•°å€¼æ•°æ®
- æ‰€æœ‰åˆ—å¿…é¡»ä¸ºæ•°å€¼ç±»å‹"""
        )
    ]
) -> CallToolResult:
    """è®¡ç®—æè¿°æ€§ç»Ÿè®¡é‡
    
    ğŸ“Š åŠŸèƒ½è¯´æ˜ï¼š
    å¯¹è¾“å…¥æ•°æ®è¿›è¡Œå…¨é¢çš„æè¿°æ€§ç»Ÿè®¡åˆ†æï¼ŒåŒ…æ‹¬é›†ä¸­è¶‹åŠ¿ã€ç¦»æ•£ç¨‹åº¦ã€åˆ†å¸ƒå½¢çŠ¶ç­‰æŒ‡æ ‡ã€‚
    
    ğŸ’¡ ä½¿ç”¨åœºæ™¯ï¼š
    - åˆæ­¥äº†è§£æ•°æ®çš„åˆ†å¸ƒç‰¹å¾
    - æ£€æŸ¥æ•°æ®è´¨é‡å’Œå¼‚å¸¸å€¼
    - ä¸ºåç»­å»ºæ¨¡æä¾›åŸºç¡€ä¿¡æ¯
    """
    try:
        # æ£€æµ‹è¾“å…¥ç±»å‹å¹¶åŠ è½½æ•°æ®
        if isinstance(data, str):
            # æ–‡ä»¶è·¯å¾„è¾“å…¥
            data_dict = await load_data_from_path(data, ctx)
        else:
            # å­—å…¸è¾“å…¥
            data_dict = data
        
        await ctx.info(f"å¼€å§‹è®¡ç®—æè¿°æ€§ç»Ÿè®¡ï¼Œå¤„ç† {len(data_dict)} ä¸ªå˜é‡")
        
        # æ•°æ®éªŒè¯
        if not data_dict:
            raise ValueError("æ•°æ®ä¸èƒ½ä¸ºç©º")
        
        df = pd.DataFrame(data_dict)
        
        # åŸºç¡€ç»Ÿè®¡é‡
        result = DescriptiveStatsResult(
            count=len(df),
            mean=df.mean().mean(),
            std=df.std().mean(),
            min=df.min().min(),
            max=df.max().max(),
            median=df.median().mean(),
            skewness=df.skew().mean(),
            kurtosis=df.kurtosis().mean()
        )
        
        # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
        correlation_matrix = df.corr().round(4)
        
        await ctx.info(f"æè¿°æ€§ç»Ÿè®¡è®¡ç®—å®Œæˆï¼Œæ ·æœ¬å¤§å°: {len(df)}")
        
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"æè¿°æ€§ç»Ÿè®¡ç»“æœï¼š\n"
                         f"æ ·æœ¬æ•°: {result.count}\n"
                         f"å‡å€¼: {result.mean:.4f}\n"
                         f"æ ‡å‡†å·®: {result.std:.4f}\n"
                         f"æœ€å°å€¼: {result.min:.4f}\n"
                         f"æœ€å¤§å€¼: {result.max:.4f}\n"
                         f"ä¸­ä½æ•°: {result.median:.4f}\n"
                         f"ååº¦: {result.skewness:.4f}\n"
                         f"å³°åº¦: {result.kurtosis:.4f}\n\n"
                         f"ç›¸å…³ç³»æ•°çŸ©é˜µï¼š\n{correlation_matrix.to_string()}"
                )
            ],
            structuredContent=result.model_dump()
        )
        
    except Exception as e:
        await ctx.error(f"è®¡ç®—æè¿°æ€§ç»Ÿè®¡æ—¶å‡ºé”™: {str(e)}")
        return CallToolResult(
            content=[TextContent(type="text", text=f"é”™è¯¯: {str(e)}")],
            isError=True
        )


@mcp.tool()
async def correlation_analysis(
    ctx: Context[ServerSession, AppContext],
    data: Annotated[
        Union[Dict[str, List[float]], str],
        Field(
            description="""æ•°æ®è¾“å…¥ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š

ğŸ“Š æ ¼å¼1ï¼šæ•°æ®å­—å…¸
{
    "é”€å”®é¢": [12000, 13500, 11800, 14200],
    "å¹¿å‘Šæ”¯å‡º": [800, 900, 750, 1000],
    "ä»·æ ¼": [99, 95, 102, 98]
}

ğŸ“ æ ¼å¼2ï¼šCSVæ–‡ä»¶è·¯å¾„
"d:/data/marketing_data.csv"

è¦æ±‚ï¼š
- è‡³å°‘åŒ…å«2ä¸ªå˜é‡
- æ‰€æœ‰å˜é‡çš„æ•°æ®ç‚¹æ•°é‡å¿…é¡»ç›¸åŒ"""
        )
    ],
    method: Annotated[
        str,
        Field(
            default="pearson",
            description="ç›¸å…³ç³»æ•°ç±»å‹ï¼špearson/spearman/kendall"
        )
    ] = "pearson"
) -> CallToolResult:
    """å˜é‡é—´ç›¸å…³æ€§åˆ†æ"""
    try:
        # æ£€æµ‹è¾“å…¥ç±»å‹å¹¶åŠ è½½æ•°æ®
        if isinstance(data, str):
            data_dict = await load_data_from_path(data, ctx)
        else:
            data_dict = data
        
        await ctx.info(f"å¼€å§‹ç›¸å…³æ€§åˆ†æ: {method}")
        
        # æ•°æ®éªŒè¯
        if not data_dict:
            raise ValueError("æ•°æ®ä¸èƒ½ä¸ºç©º")
        if len(data_dict) < 2:
            raise ValueError("è‡³å°‘éœ€è¦2ä¸ªå˜é‡è¿›è¡Œç›¸å…³æ€§åˆ†æ")
        
        df = pd.DataFrame(data_dict)
        correlation_matrix = df.corr(method=method)
        
        await ctx.info("ç›¸å…³æ€§åˆ†æå®Œæˆ")
        
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"{method.title()}ç›¸å…³ç³»æ•°çŸ©é˜µï¼š\n{correlation_matrix.round(4).to_string()}"
                )
            ]
        )
        
    except Exception as e:
        await ctx.error(f"ç›¸å…³æ€§åˆ†æå‡ºé”™: {str(e)}")
        return CallToolResult(
            content=[TextContent(type="text", text=f"é”™è¯¯: {str(e)}")],
            isError=True
        )


def create_mcp_server() -> FastMCP:
    """åˆ›å»ºå¹¶è¿”å›MCPæœåŠ¡å™¨å®ä¾‹"""
    return mcp